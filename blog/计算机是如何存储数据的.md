## 为什么要学编程基础

> 因为你首先是程序员，其次才是前端。

一个程序员需要知道

>硬件与软件：计算机的运行原理（《[编码](https://book.douban.com/subject/4822685/)》），以及大学计算机相关课程，例如《计算机组成原理》、《计算机网络》，我在上大学的时候，老师有讲过计算机原理
>
>最大的软件：操作系统（[维基百科](https://zh.wikipedia.org/wiki/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F)）**了解操作系统由什么构成的**
>
>自己写软件：数据结构 & 算法（《[数据结构与算法分析](https://book.douban.com/subject/1139426/)》）**数据结构与算法分析，排序算法**
>
>多人写软件：软件工程（[代码大全](https://book.douban.com/subject/1477390/)）

## 前端为什么要学编程基础?

- **操作系统**运行在硬件之上
- **浏览器**运行在**操作系统**之上，不仅仅是浏览器，所有的软件都是运行在操作系统之上的。
- HTML/CSS/JS运行在**浏览器**之上
- HTML/CSS/JS和数据都来自**服务器**

存在**三层依赖**,所以我们前端需要学习编程基础,我们才会知道

- CSS/JS是怎样运行的?
- JS的变量存储在哪里?
- 数据怎么从服务器获取?

## 计算机: 二进制的世界

1. 为什么计算机只能存储0和1？
2. 如何存储0和1
3. 如何存储数字
4. 如何存储字符
5. 如何存储中文
6. 如何存储所有字符
7. 如何用更少的空间来存储


### 1. 为什么计算机只能存储0和1？
>这其中涉及到很多硬件知识，简单的来说，因为电脑是**集成电路**，内存微观上是无数小开关，或者是小电池，而“0”和“1”正好分别代表“开”和“关”（或者是“通电”和“不通电”），就好像家里的电灯开关只有开和关一样。所以，电脑的本质决定了它必须是二进制，只能存储0和1

### 2. 如何存储0和1

> 计算机存储过程，其实就是给小电池不断充电的过程，因为小电池自身存在耗电（好比家里的南孚电池放久了不用自己会消耗电量一样）。那么，既然小电池自己会耗电，又要不断充电，如何判断它是的状态是0和1呢？规则是：当小电池电量大于50%，为1；电量小于50%，则为0。因为计算机的充电速率是纳秒级（10^-9）,即一次充电过程为：刷新1次/10^-9S。

计算机首先**纵向**,从上往下选中8个点,然后横向输入电量

![内存如何存储0和1.png](https://upload-images.jianshu.io/upload_images/11616333-16ac2c5b9640e395.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)


存储

- 1就充电(变成红色)
- 0就不充电(不变色)

读取

- 电量大于50% 就是1
- 电量小于50% 就是0

通过这样内存就实现可以存储0和1

### 2. 如何存储数字*

计算机只存储0和1,所以存储数字,需要将数字转换为二进制的0和1

#### 十进制 --> 二进制

37(10) == 100101(2)	括号里面的数字代表是什么进制

`*`代表是乘,`^`代表是多少次方,`?`代表未知,需要求出来 

```
37(10)  = 3 * 10^1 + 7 * 10^0
		= n1 * 2^? + n2 * 2^?
		= 32 + 4 + 1
		= 1 * 2^5 + 1 * 2^2 + 1 * 2^0
		= 1 * 2^5 + 0 * 2^4 + 0 * 2^3 + 1 * 2^2 + 0 * 2^1 + 1 * 2^0
		= 100101(2)
```

-37(10) == -100101(2)

负数会以[补码](https://jrg-team.github.io/jrg-tasks/lessons/%E7%BC%96%E7%A8%8B%E5%88%9D%E7%BA%A7/index.html)的形式存储,比较复杂,这里不做多讲

0.75(10) == 0.11(2)

```
0.75(10)  = 7 * 1/10 + 5 * 1/10^2
		  = n1 * 1/2 + n2 * 1/4
		  = 0.5 + 0.25
		  = 1* 1/2 + 1 * 1/4
		  = 0.11(2)
```

小Tips:

为了方便书写,一般会将二进制写为十六进制

二进制 --> 十六进制,每四个二进制代表一个十六进制数

举个例子下面的转换可以跟这个例子推出来:

1111(2) --> F(16)

```
1111(2) = 2^3 + 2^2 + 2^1 + 2^0 = F(16)
```

| 二进制 | 十六进制 |
| ------ | -------- |
| 0001   | 1        |
| 0010   | 2        |
| 0011   | 3        |
| 0100   | 4        |
| 0101   | 5        |
| 0110   | 6        |
| 0111   | 7        |
| 1000   | 8        |
| 1001   | 9        |
| 1010   | A        |
| 1011   | B        |
| 1100   | C        |
| 1101   | D        |
| 1110   | E        |
| 1111   | F        |

### 3.如何存储字符*

将每个字符编号

ASCII(**A**merican **S**tandard **C**ode for **I**nformation **I**nterchange,**美国信息交换标准代码**)

> 美国信息交换标准代码是基于[拉丁字母](https://zh.wikipedia.org/wiki/%E6%8B%89%E4%B8%81%E5%AD%97%E6%AF%8D)的一套[计算机](https://zh.wikipedia.org/wiki/%E7%94%B5%E8%84%91)[编码](https://zh.wikipedia.org/wiki/%E7%BC%96%E7%A0%81)系统。它主要用于显示[现代英语](https://zh.wikipedia.org/wiki/%E7%8F%BE%E4%BB%A3%E8%8B%B1%E8%AA%9E)，而其扩展版本[EASCII](https://zh.wikipedia.org/wiki/EASCII)则可以部分支持其他[西欧](https://zh.wikipedia.org/wiki/%E8%A5%BF%E6%AC%A7)[语言](https://zh.wikipedia.org/wiki/%E8%AF%AD%E8%A8%80)，并等同于国际标准**ISO/IEC 646**。

你想存储a,就需要存储97(10)对应的二进制

```
97(10)  = 9 * 10^1 + 7 * 10^0
		= n1 * 2^? + n2 * 2^?
		= 64 + 32 + 1
		= 1 * 2^6 + 1 * 2^5 + 1 * 2^0
		= 01100001(2) == 61(16)
```

你想存储A,就需要存储65(10)对应的二进制

```
65(10)  = 6 * 10^1 + 5 * 10^0
		= n1 * 2^? + n2 * 2^?
		= 64 + 1
		= 1 * 2^6  + 1 * 2^0
		= 01000001(2) == 41(16)
```

通过上面的例子说明计算机会认为A和a是不一样,因为所对应的ASCII不同

### 4. 如何存储中文

- [GB 2312 中国国家标准简体中文字符集](https://zh.wikipedia.org/wiki/GB_2312)
- [微软推出的GBK 字符集](https://zh.wikipedia.org/wiki/%E6%B1%89%E5%AD%97%E5%86%85%E7%A0%81%E6%89%A9%E5%B1%95%E8%A7%84%E8%8C%83)(存储生僻字、繁体字、日语、朝鲜语等)
- GB2312 共收录 **6763 个汉字**，同时收录了包括拉丁字母、希腊字母、日文平假名及片假名字母、俄语西里尔字母在内的 **682 个字符**。

### 5.如何存储所有字符

- [Unicode 字符集](https://zh.wikipedia.org/wiki/Unicode)
- unciode万国码,将全球字符编号,包括中日韩文字、藏文、盲文、楔形文字、 [颜文字](https://zh.wikipedia.org/wiki/%E8%A1%A8%E6%83%85%E7%AC%A6%E8%99%9F%E5%88%97%E8%A1%A8#ref_U1F600_as_of_Unicode_version)`:-)`、 绘文字

### 6. 如何将Unicode存到计算机里

#### 低性价比

a -> 00000000 00000000 00000000 011000012 = 0061(16)

你 -> 00000000 00000000 01001111 011000002 = 4F60(16)

#### 高性价比 UTF-8

a -> 01100001

你-> **111**00100 **1**0111101 **1**0100000

低性价比,因为计算机需要使用4个字节来存储

下面解释一下"你"的UTF-8

```
//Unicode
你 -> 00000000 00000000 01001111 011000002
//utf-8
你-> 11100100 10111101 10100000
//1110 表示告诉计算机,读取的时候往后读三个字节,每个字节开头都是10,除我之外,10都是表示我跟着前面的
```

#### UTF-8 是一种编码方式，不是字符集

[UTF-8的编码方式](https://zh.wikipedia.org/wiki/UTF-8#UTF-8.E7.9A.84.E7.B7.A8.E7.A2.BC.E6.96.B9.E5.BC.8F)

### 现实问题

- 为什么有些中文软件喜欢用GBK,不用Unicode?
  - 因为在93年-99年都在使用GB 13000,GBK这两种
- Javascript使用Unicode字符集,但是没有使用UTF-8编码
  - Javascript用了UCS-2编码,因为1995年UTF-16还没被发明出来,Javascript也不想使用 UTF-32,[Unicode与JavaScript详解](http://www.ruanyifeng.com/blog/2014/12/unicode.html)
  - 出现的后果:ES5 无法表示 \uFFFF 之后的字符（如 \u1D306）,某些情况下会出 bug,[Javascript有个Unicode的天坑](http://www.alloyteam.com/2016/12/javascript-has-a-unicode-sinkhole/)